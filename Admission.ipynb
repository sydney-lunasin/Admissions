{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Prediction of Graduate Admissions\n",
    "\n",
    "<img src=\"admission.jpg\" width=500 height = 280/>\n",
    "\n",
    "**Data to be used**: `Admission_Predict.csv`\n",
    "\n",
    "Following is the description of columns in `Admission_Predict.csv` file:\n",
    "\n",
    "<TABLE CAPTION=\"Mobile Dataset\">\n",
    "<TR><TD><B>Variable</B></TD><TD><B>Description</B></TD></TR>\n",
    "<TR><TD>GRE Score</TD><TD>GRE Scores (out of 340)</TD></TR>\n",
    "<TR><TD>TOEFL Score</TD><TD>TOEFL Scores (out of 120)</TD></TR>\n",
    "<TR><TD>University Rating</TD><TD>University Rating (out of 5)</TD></TR>\n",
    "<TR><TD>SOP</TD><TD>Quality of Statement of Purpose (out of 5)</TD></TR>\n",
    "<TR><TD>LOR</TD><TD>Quality of Letters of Recommendation (out of 5)</TD></TR>\n",
    "<TR><TD>CGPA</TD><TD>Undergraduate GPA (out of 10)</TD></TR>   \n",
    "<TR><TD>Research</TD><TD>Research Experience (either Yes or No)</TD></TR>\n",
    "<TR><TD>Chances of Admit</TD><TD>Chance of Admit (ranging from 0 to 1)</TD></TR>\n",
    "</TABLE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                  # Pandas\n",
    "import numpy as np                   # Numpy\n",
    "from matplotlib import pyplot as plt # Matplotlib\n",
    "\n",
    "# Package to implement ML Algorithms\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor # Random Forest\n",
    "\n",
    "# Import MAPIE to calculate prediction intervals\n",
    "from mapie.regression import MapieRegressor\n",
    "\n",
    "# To calculate coverage score\n",
    "from mapie.metrics import regression_coverage_score\n",
    "\n",
    "# Package for data partitioning\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Package to record time\n",
    "import time\n",
    "\n",
    "# Module to save and load Python objects to and from files\n",
    "import pickle \n",
    "\n",
    "# Ignore Deprecation Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display inline plots as vector-based (svg)\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install MAPIE via `pip`**:\n",
    "\n",
    "`!pip install mapie`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>No</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA Research  \\\n",
       "0        337          118                  4  4.5  4.5  9.65      Yes   \n",
       "1        324          107                  4  4.0  4.5  8.87      Yes   \n",
       "2        316          104                  3  3.0  3.5  8.00      Yes   \n",
       "3        322          110                  3  3.5  2.5  8.67      Yes   \n",
       "4        314          103                  2  2.0  3.0  8.21       No   \n",
       "\n",
       "   Chance of Admit  \n",
       "0             0.92  \n",
       "1             0.76  \n",
       "2             0.72  \n",
       "3             0.80  \n",
       "4             0.65  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data\n",
    "df = pd.read_csv('Admission_Predict.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select input and output features\n",
    "X = df.drop(columns = ['Chance of Admit'])\n",
    "y = df['Chance of Admit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research_No</th>\n",
       "      <th>Research_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  Research_No  \\\n",
       "0        337          118                  4  4.5  4.5  9.65        False   \n",
       "1        324          107                  4  4.0  4.5  8.87        False   \n",
       "2        316          104                  3  3.0  3.5  8.00        False   \n",
       "3        322          110                  3  3.5  2.5  8.67        False   \n",
       "4        314          103                  2  2.0  3.0  8.21         True   \n",
       "\n",
       "   Research_Yes  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4         False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding for categorical variables\n",
    "X_encoded = pd.get_dummies(X)\n",
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data partitioning into train and test sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_encoded, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model\n",
    "reg = RandomForestRegressor(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.1502091884613037s\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "start = time.time()            # Start Time\n",
    "reg.fit(train_X, train_y)  \n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Prediction Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared on Test Set: 0.79\n",
      "RMSE on Test Set: 0.07\n"
     ]
    }
   ],
   "source": [
    "# Predict Test Set\n",
    "y_pred = reg.predict(test_X)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "r2 = sklearn.metrics.r2_score(test_y, y_pred)\n",
    "print('R-squared on Test Set: %0.2f' %r2)\n",
    "\n",
    "RMSE_test = sklearn.metrics.root_mean_squared_error(test_y, y_pred)\n",
    "print('RMSE on Test Set: %0.2f' %RMSE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of Residuals/Errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the residuals by subtracting the predicted values from the actual test values\n",
    "all_residuals = test_y - y_pred\n",
    "\n",
    "# Set up the figure with custom size and resolution (DPI)\n",
    "plt.figure(figsize=(6, 4), dpi = 150)\n",
    "\n",
    "# Plot the histogram of residuals\n",
    "plt.hist(all_residuals, bins = 25, color = 'lime', edgecolor = 'black')\n",
    "\n",
    "# Label X and Y axes\n",
    "plt.xlabel('Residuals', fontsize = 14)\n",
    "plt.ylabel('# of Test Datapoints', fontsize = 14)\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Distribution of Residuals', fontsize = 16)\n",
    "\n",
    "# Adjust the font size of x and y ticks\n",
    "plt.xticks(fontsize = 10)\n",
    "plt.yticks(fontsize = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter Plot of Predicted Vs. Actual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the figure size and resolution\n",
    "plt.figure(figsize = (6, 4), dpi = 150)\n",
    "\n",
    "# Scatter plot of actual vs predicted values\n",
    "plt.scatter(test_y, y_pred, color = 'blue', alpha = 0.6, edgecolor = 'black', s = 40)\n",
    "\n",
    "# 45-degree reference line (perfect predictions)\n",
    "plt.plot([min(test_y), max(test_y)], [min(test_y), max(test_y)], color = 'red', linestyle = '--', lw = 2)\n",
    "\n",
    "# Axis labels and title\n",
    "plt.xlabel('Actual Values', fontsize = 10)\n",
    "plt.ylabel('Predicted Values', fontsize = 10)\n",
    "plt.title('Predicted vs Actual Values', fontsize = 12)\n",
    "\n",
    "# Adjust ticks\n",
    "plt.xticks(fontsize = 10)\n",
    "plt.yticks(fontsize = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing importance values from the trained model\n",
    "importance = reg.feature_importances_\n",
    "\n",
    "# Storing feature importance as a dataframe\n",
    "feature_imp = pd.DataFrame(list(zip(train_X.columns, importance)),\n",
    "               columns = ['Feature', 'Importance'])\n",
    "\n",
    "feature_imp = feature_imp.sort_values('Importance', ascending = False).reset_index(drop = True)\n",
    "\n",
    "# Bar plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.barh(feature_imp['Feature'], feature_imp['Importance'], color = ['red', 'lime'])\n",
    "\n",
    "plt.xlabel(\"Importance\", fontsize = 12)\n",
    "plt.ylabel(\"Input Feature\", fontsize = 12)\n",
    "plt.title('Which features are the most important for predicting admission chances?', fontsize = 12) \n",
    "plt.yticks(fontsize = 10) # fontsize of yticks\n",
    "plt.xticks(fontsize = 10) # fontsize of xticks\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Intervals for Regression\n",
    "<img src=\"Prediction_Interval.png\" width=\"500\" style=\"float: center\"/>\n",
    "\n",
    "#### **What is a Prediction Interval?**\n",
    "- It is a **range of values** within which a new observation is expected to fall with a **certain probability**, given the existing data and model.\n",
    "\n",
    "- **Probability**: The width of the prediction interval depends on the **desired confidence level**, (e.g., 95%), with higher confidence levels leading to wider intervals.\n",
    "\n",
    "#### **Confidence Level of Prediction Interval**\n",
    "\n",
    "- The confidence level of a prediction interval indicates the probability that the interval will contain the true value of the parameter being estimated.\n",
    "\n",
    "- Mathematically, the confidence level of a prediction interval is denoted by $ (1 - \\alpha) \\times 100\\% $, where $ \\alpha $ is the significance level.\n",
    "\n",
    "#### **Why Prediction Intervals are Useful?**\n",
    "\n",
    "- **Uncertainty Quantification**: They provide a measure of the uncertainty in individual predictions, which is crucial for risk assessment and decision-making.\n",
    "\n",
    "- **Communication**: They are an effective tool for communicating the uncertainty in predictions to stakeholders, making the model's predictions more interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Prediction Intervals using MAPIE Regressor**\n",
    "\n",
    "***MAPIE: Model Agnostic Prediction Interval Estimator***\n",
    "\n",
    "- It is a Python library designed to estimate prediction intervals in a **model-agnostic way**.\n",
    "- It can be used with **any machine learning model**, including linear models, decision trees, ensemble methods, and neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MAPIE regressor\n",
    "mapie = MapieRegressor(estimator = reg, # Prediction model to use\n",
    "                       n_jobs = -1,\n",
    "                       random_state = 42)\n",
    "\n",
    "# Fit mapie regressor on training data\n",
    "start = time.time()  \n",
    "mapie.fit(train_X, train_y)\n",
    "stop = time.time()             \n",
    "print(f\"Training time: {stop - start}s\")\n",
    "\n",
    "alpha = 0.1 # For 90% confidence level\n",
    "\n",
    "# Use mapie.predict() to get predicted values and intervals\n",
    "y_test_pred, y_test_pis = mapie.predict(test_X, alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted values\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Intervals\n",
    "y_test_pis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing results in a dataframe\n",
    "predictions = test_y.to_frame()\n",
    "predictions.columns = ['Actual Value']\n",
    "predictions[\"Predicted Value\"] = y_test_pred.round(2)\n",
    "predictions[\"Lower Value\"] = y_test_pis[:, 0].round(2)\n",
    "predictions[\"Upper Value\"] = y_test_pis[:, 1].round(2)\n",
    "\n",
    "# Take a quick look\n",
    "predictions.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Coverage Calculation**\n",
    "- **Coverage** refers to the proportion of true/actual values that fall within the prediction intervals generated by a model.\n",
    "\n",
    "- It is a measure of how well the prediction intervals capture the actual values.\n",
    "\n",
    "  $\\text{Coverage} = \\frac{\\text{Number of actual values within prediction intervals}}{\\text{Total number of actual values}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = regression_coverage_score(test_y,           # Actual values\n",
    "                                     y_test_pis[:, 0], # Lower bound of prediction intervals\n",
    "                                     y_test_pis[:, 1]) # Upper bound of prediction intervals\n",
    "\n",
    "coverage_percentage = coverage * 100\n",
    "print(f\"Coverage: {coverage_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the predictions by 'Actual Value' for better visualization and reset the index\n",
    "sorted_predictions = predictions.sort_values(by=['Actual Value']).reset_index(drop=True)\n",
    "\n",
    "# Create a figure and axis object with specified size and resolution\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# Plot the actual values with green dots\n",
    "plt.plot(sorted_predictions[\"Actual Value\"], 'go', markersize=3, label=\"Actual Value\")\n",
    "\n",
    "# Fill the area between the lower and upper bounds of the prediction intervals with semi-transparent green color\n",
    "plt.fill_between(np.arange(len(sorted_predictions)),\n",
    "                 sorted_predictions[\"Lower Value\"],\n",
    "                 sorted_predictions[\"Upper Value\"],\n",
    "                 alpha=0.2, color=\"green\", label=\"Prediction Interval\")\n",
    "\n",
    "# Set font size for x and y ticks\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Set the limit for the x-axis to cover the range of samples\n",
    "plt.xlim([0, len(sorted_predictions)])\n",
    "\n",
    "# Label the x-axis and y-axis with appropriate font size\n",
    "plt.xlabel(\"Samples\", fontsize=10)\n",
    "plt.ylabel(\"Target\", fontsize=10)\n",
    "\n",
    "# Add a title to the plot, including the coverage percentage, with bold formatting\n",
    "plt.title(f\"Prediction Intervals and Coverage: {coverage_percentage:.2f}%\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "# Add a legend to the plot, placed in the upper left, with specified font size\n",
    "plt.legend(loc=\"upper left\", fontsize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the file where we want to write the model\n",
    "reg_pickle = open('reg_admission.pickle', 'wb') \n",
    "\n",
    "# Write RF model to the file\n",
    "pickle.dump(mapie, reg_pickle) \n",
    "\n",
    "# Close the file\n",
    "reg_pickle.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
